{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KDD99 Deep Nueral Network Intrusion Detection\n",
    "\n",
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "from IPython.display import clear_output as clr\n",
    "from sklearn.utils import class_weight\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras as kk\n",
    "import keras.models as km\n",
    "import keras.layers as kl\n",
    "import keras.optimizers as ko\n",
    "import keras.regularizers as kr\n",
    "from sklearn.model_selection import train_test_split as tts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting working Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working Directory :  /media/abhikcr/New Volume/Study/M.tech 1st Sem/Cyber Security/Homeworks/KDD/extracted/\n"
     ]
    }
   ],
   "source": [
    "dir_path = (os.getcwd()+'\\\\').replace(\"\\\\\",\"/\")\n",
    "print(\"Working Directory : \", dir_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fucntions to Load files.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_len(fname):\n",
    "    with open(fname) as f:\n",
    "        for i, l in enumerate(f):\n",
    "            pass\n",
    "    return i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readlines(fname, start, end):\n",
    "#     fname = 'kddcup.data.corrected'\n",
    "    file = open(fname)\n",
    "    batch = []\n",
    "    r = end - start\n",
    "    for i in range(start):\n",
    "        line = file.readline()\n",
    "    for i in range(r):\n",
    "        line = file.readline()\n",
    "        batch.append(line.split(','))\n",
    "    file.close()\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmreadlines(fname, size):\n",
    "#     fname = 'kddcup.data.corrected'\n",
    "    Nobs = file_len(fname)\n",
    "    choices = np.sort(np.random.choice(Nobs,size, replace=False))\n",
    "    \n",
    "    k = 0\n",
    "    \n",
    "    file = open(fname)\n",
    "    batch = []\n",
    "    \n",
    "    \n",
    "    for i in range(Nobs):\n",
    "\n",
    "        line = file.readline()\n",
    "        if(k<choices.shape[0]):\n",
    "            if(choices[k] == i):\n",
    "                batch.append(line.split(','))\n",
    "                k = k+1\n",
    "            else:\n",
    "                pass\n",
    "        else:\n",
    "            break;\n",
    "    \n",
    "    file.close()\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Splitting data in train and test files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_file(fname, trainname, testname):\n",
    "    Nobs = file_len(fname)\n",
    "    tfp = int(Nobs*0.25)\n",
    "    choices = np.sort(np.random.choice(Nobs,tfp, replace=False))\n",
    "    k = 0\n",
    "    file = open(fname)\n",
    "    filetr = open(trainname, 'w')\n",
    "    filets = open(testname, 'w')\n",
    "    \n",
    "    for i in range(Nobs):\n",
    "        \n",
    "        line = file.readline()\n",
    "        if(k<choices.shape[0]):\n",
    "            if(choices[k] == i):\n",
    "                filets.write(line)\n",
    "                k = k+1\n",
    "            else:\n",
    "                filetr.write(line)\n",
    "        else:\n",
    "            filetr.write(line)\n",
    "            \n",
    "    filets.close()\n",
    "    filetr.close()\n",
    "    file.close()\n",
    "    return Nobs, choices.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Already spliited dont repeat...\n",
    "split = False\n",
    "if(split):\n",
    "    Nobs, test_size = split_file('kddcup.data.corrected', 'train','test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading trainning data batchwise..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myArrayConverter(arr):\n",
    "    '''\n",
    "    To convert string to floats\n",
    "    '''\n",
    "    convertArr = []\n",
    "    for s in arr.ravel():    \n",
    "        try:\n",
    "            value = float(s)\n",
    "        except ValueError:\n",
    "            value = s\n",
    "        convertArr.append(value)\n",
    "    return array(convertArr,dtype=object).reshape(arr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file names\n",
    "trainfile = 'train'\n",
    "testfile = 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data has 3673824 observations\n"
     ]
    }
   ],
   "source": [
    "train_size = file_len(trainfile)\n",
    "print('Training data has',train_size, 'observations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100000\n",
    "n_batches = int(np.ceil(train_size/batch_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bacth Processing...\n",
    "\n",
    "Function to convert categorical Y values to one_hot vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(a, num_classes):\n",
    "    return np.squeeze(np.eye(num_classes)[a.reshape(-1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating label ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list = pd.read_csv('training_attack_types', delimiter = ' ', index_col = False, names =['type', 'category'])\n",
    "label_list = label_list.assign(id_type=(label_list['type']).astype('category').cat.codes)\n",
    "label_list = label_list.assign(id_cat=(label_list['category']).astype('category').cat.codes)\n",
    "label_list = label_list.append({'type':'normal', 'category':'normal','id_type':'-1','id_cat':'-1'}, ignore_index = True)\n",
    "label_list['id_type'] = label_list['id_type'].astype(int)+1\n",
    "label_list['id_cat'] = label_list['id_cat'].astype(int)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>category</th>\n",
       "      <th>id_type</th>\n",
       "      <th>id_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>back</td>\n",
       "      <td>dos</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>buffer_overflow</td>\n",
       "      <td>u2r</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ftp_write</td>\n",
       "      <td>r2l</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>guess_passwd</td>\n",
       "      <td>r2l</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>imap</td>\n",
       "      <td>r2l</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ipsweep</td>\n",
       "      <td>probe</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>land</td>\n",
       "      <td>dos</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>loadmodule</td>\n",
       "      <td>u2r</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>multihop</td>\n",
       "      <td>r2l</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>neptune</td>\n",
       "      <td>dos</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>nmap</td>\n",
       "      <td>probe</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>perl</td>\n",
       "      <td>u2r</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>phf</td>\n",
       "      <td>r2l</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>pod</td>\n",
       "      <td>dos</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>portsweep</td>\n",
       "      <td>probe</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>rootkit</td>\n",
       "      <td>u2r</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>satan</td>\n",
       "      <td>probe</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>smurf</td>\n",
       "      <td>dos</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>spy</td>\n",
       "      <td>r2l</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>teardrop</td>\n",
       "      <td>dos</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>warezclient</td>\n",
       "      <td>r2l</td>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>warezmaster</td>\n",
       "      <td>r2l</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               type category  id_type  id_cat\n",
       "0              back      dos        1       1\n",
       "1   buffer_overflow      u2r        2       4\n",
       "2         ftp_write      r2l        3       3\n",
       "3      guess_passwd      r2l        4       3\n",
       "4              imap      r2l        5       3\n",
       "5           ipsweep    probe        6       2\n",
       "6              land      dos        7       1\n",
       "7        loadmodule      u2r        8       4\n",
       "8          multihop      r2l        9       3\n",
       "9           neptune      dos       10       1\n",
       "10             nmap    probe       11       2\n",
       "11             perl      u2r       12       4\n",
       "12              phf      r2l       13       3\n",
       "13              pod      dos       14       1\n",
       "14        portsweep    probe       15       2\n",
       "15          rootkit      u2r       16       4\n",
       "16            satan    probe       17       2\n",
       "17            smurf      dos       18       1\n",
       "18              spy      r2l       19       3\n",
       "19         teardrop      dos       20       1\n",
       "20      warezclient      r2l       21       3\n",
       "21      warezmaster      r2l       22       3\n",
       "22           normal   normal        0       0"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nClasses = label_list.shape[0]\n",
    "label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample batching....\n",
    "#currpos = 0\n",
    "# batch = readlines(trainfile, currpos, currpos + batch_size)\n",
    "batch = rmreadlines(trainfile, batch_size)\n",
    "batchdf = pd.DataFrame(np.array(batch)).astype(float, errors='ignore')\n",
    "for col in batchdf.columns:\n",
    "    batchdf[col] = batchdf[col].astype('float64', errors = 'ignore') \n",
    "\n",
    "batcharr = batchdf.values\n",
    "\n",
    "X = batcharr[:,:-1]\n",
    "\n",
    "Y = batcharr[:,-1]\n",
    "Y_num = np.ones(Y.shape)\n",
    "Y_num[Y == 'normal.\\n'] = 0\n",
    "Y_cat = Y_num.copy()\n",
    "Y_type = Y_num.copy()\n",
    "\n",
    "for i in label_list['type']:\n",
    "    Y_cat[Y == i+str('.\\n')] = label_list[label_list['type'] == i]['id_cat']\n",
    "    Y_type[Y == i+str('.\\n')] = label_list[label_list['type'] == i]['id_type']\n",
    "\n",
    "Y_num_hot = one_hot(Y_num.astype(int), 2)\n",
    "Y_cat_hot = one_hot(Y_cat.astype(int), 5)\n",
    "Y_type_hot = one_hot(Y_type.astype(int), 23)\n",
    "\n",
    "X_new_hot = np.delete(X,[1,2,3],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['back.\\n', 'guess_passwd.\\n', 'imap.\\n', 'ipsweep.\\n', 'land.\\n',\n",
       "       'neptune.\\n', 'nmap.\\n', 'normal.\\n', 'pod.\\n', 'portsweep.\\n',\n",
       "       'satan.\\n', 'smurf.\\n', 'teardrop.\\n', 'warezclient.\\n',\n",
       "       'warezmaster.\\n'], dtype=object)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# just to see class imbalance bacth wise....\n",
    "np.unique(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch class imbalance reweighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "cw_num = class_weight.compute_class_weight('balanced',np.unique(Y_num),Y_num)\n",
    "cw_cat = class_weight.compute_class_weight('balanced',np.unique(Y_cat),Y_cat)\n",
    "cw_type = class_weight.compute_class_weight('balanced',np.unique(Y_type),Y_type)\n",
    "cws_num = np.arange(2)*0.0\n",
    "cws_num[np.unique(Y_num).astype(int)] = cw_num\n",
    "cws_cat = np.arange(5)*0.0\n",
    "cws_cat[np.unique(Y_cat).astype(int)] = cw_cat\n",
    "cws_type = np.arange(23)*0.0\n",
    "cws_type[np.unique(Y_type).astype(int)] = cw_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "N,D = X_new_hot.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(input_shape):\n",
    "    \n",
    "    \n",
    "    xin = kl.Input(shape = input_shape)\n",
    "    x = kl.Dense(128, activation='relu',kernel_regularizer=kr.l2(0.01))(xin)\n",
    "#     x = kl.Dense(64, activation='relu',kernel_regularizer=kr.l2(0.01))(x)\n",
    "    x1 = kl.Dense(32, activation='relu',kernel_regularizer=kr.l2(0.01))(x)\n",
    "    x1out = kl.Dense(2, activation='softmax', name = 'y1out',kernel_regularizer=kr.l2(0.01))(x1)\n",
    "    \n",
    "    x2 = kl.Dense(32, activation='relu',kernel_regularizer=kr.l2(0.01))(x)\n",
    "    \n",
    "    x2cat = kl.Concatenate(axis=-1)([x1out, x2])\n",
    "    \n",
    "    x2out = kl.Dense(5, activation='softmax', name = 'y2out',kernel_regularizer=kr.l2(0.01))(x2cat)\n",
    "    \n",
    "    x3cat = kl.Concatenate(axis=-1)([x2out, x])\n",
    "    \n",
    "    x3 = kl.Dense(64, activation='relu',kernel_regularizer=kr.l2(0.01))(x3cat)\n",
    "    \n",
    "    x3out = kl.Dense(23, activation='softmax', name = 'y3out',kernel_regularizer=kr.l2(0.01))(x3)\n",
    "    \n",
    "    model = km.Model(\n",
    "        inputs=xin,\n",
    "        outputs=[x1out,x2out,x3out],\n",
    "        name=\"fashionnet\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model([D])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = {\n",
    "    \"y1out\": \"categorical_crossentropy\",\n",
    "    \"y2out\": \"categorical_crossentropy\",\n",
    "    \"y3out\": \"categorical_hinge\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "lossWeights = {\"y1out\": 1.0, \"y2out\": 1.0, \"y3out\": 1.0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = ko.Adam(lr=0.01, beta_1=0.9, beta_2=0.999, epsilon=None, decay=1.0e-9, amsgrad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=opt, loss=losses, loss_weights=lossWeights, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            (None, 38)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 128)          4992        input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 32)           4128        dense_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "y1out (Dense)                   (None, 2)            66          dense_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 32)           4128        dense_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 34)           0           y1out[0][0]                      \n",
      "                                                                 dense_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "y2out (Dense)                   (None, 5)            175         concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 133)          0           y2out[0][0]                      \n",
      "                                                                 dense_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 64)           8576        concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "y3out (Dense)                   (None, 23)           1495        dense_17[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 23,560\n",
      "Trainable params: 23,560\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "24606/24606 [==============================] - 2s 64us/step - loss: 0.1277 - y1out_loss: 0.0028 - y2out_loss: 0.0098 - y3out_loss: 0.0012 - y1out_acc: 0.9994 - y2out_acc: 0.9994 - y3out_acc: 0.9994\n"
     ]
    }
   ],
   "source": [
    "# sample training...single epoch\n",
    "\n",
    "his = model.fit(X_new_hot,{\"y1out\": Y_num_hot, \"y2out\": Y_cat_hot, \"y3out\": Y_type_hot},epochs=1, batch_size = 1000\n",
    "          ,class_weight={\"y1out\": cws_num, \"y2out\": cws_cat, \"y3out\": cws_type})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading pretrained model..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = km.load_model('model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training model\n",
    "\n",
    "\n",
    "> Dont need to train if you loaded pretrained model...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Dont need to run if you are using pretrained model...\n",
    "\n",
    "Use trained model and keep train = False  it will take some time to train on normal laptops\n",
    "'''\n",
    "\n",
    "train= False\n",
    "\n",
    "if(train):\n",
    "    total_iterations = 1 # change to 200 or high if not trained even a bit...\n",
    "\n",
    "    for epochs in range(total_iterations):\n",
    "\n",
    "        batch_size = 100000\n",
    "        batch = rmreadlines(trainfile, batch_size)\n",
    "        batchdf = pd.DataFrame(np.array(batch)).astype(float, errors='ignore')\n",
    "\n",
    "        for col in batchdf.columns:\n",
    "            batchdf[col] = batchdf[col].astype('float64', errors = 'ignore') \n",
    "\n",
    "        batcharr = batchdf.values\n",
    "\n",
    "        X = batcharr[:,:-1]\n",
    "        Y = batcharr[:,-1]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        print('\\nBatch Size :', X.shape[0], 'at iteration :', epochs)\n",
    "\n",
    "        Y_num = np.ones(Y.shape)\n",
    "        Y_num[Y == 'normal.\\n'] = 0\n",
    "\n",
    "        Y_cat = Y_num.copy()\n",
    "        Y_type = Y_num.copy()\n",
    "        for i in label_list['type']:\n",
    "            Y_cat[Y == i+str('.\\n')] = label_list[label_list['type'] == i]['id_cat']\n",
    "            Y_type[Y == i+str('.\\n')] = label_list[label_list['type'] == i]['id_type']\n",
    "\n",
    "        Y_num_hot = one_hot(Y_num.astype(int), 2)\n",
    "        Y_cat_hot = one_hot(Y_cat.astype(int), 5)\n",
    "        Y_type_hot = one_hot(Y_type.astype(int), 23)\n",
    "\n",
    "        X_new_hot = np.delete(X,[1,2,3],1)\n",
    "\n",
    "        print(np.unique(Y_num), np.unique(Y_cat),np.unique(Y_type))\n",
    "\n",
    "        cw_num = class_weight.compute_class_weight('balanced',\n",
    "                                             np.unique(Y_num),\n",
    "                                             Y_num)\n",
    "        cw_cat = class_weight.compute_class_weight('balanced',\n",
    "                                                         np.unique(Y_cat),\n",
    "                                                         Y_cat)\n",
    "        cw_type = class_weight.compute_class_weight('balanced',\n",
    "                                                         np.unique(Y_type),\n",
    "                                                         Y_type)\n",
    "\n",
    "        cws_num = np.arange(2)*0.0\n",
    "        cws_num[np.unique(Y_num).astype(int)] = cw_num\n",
    "        # cws_num\n",
    "\n",
    "        cws_cat = np.arange(5)*0.0\n",
    "        cws_cat[np.unique(Y_cat).astype(int)] = cw_cat\n",
    "        # cws_cat\n",
    "\n",
    "        cws_type = np.arange(23)*0.0\n",
    "        cws_type[np.unique(Y_type).astype(int)] = cw_type\n",
    "\n",
    "        if(X_new_hot.shape[1]!=D or np.unique(Y).shape[0] == 1):\n",
    "            continue;\n",
    "\n",
    "        if((epochs+1)%3 == 0):\n",
    "            clr()\n",
    "\n",
    "        model.fit(X_new_hot,{\"y1out\": Y_num_hot, \"y2out\": Y_cat_hot, \"y3out\": Y_type_hot},epochs=1, batch_size=1000, validation_split=0.33\n",
    "                 ,class_weight={\"y1out\": cws_num, \"y2out\": cws_cat, \"y3out\": cws_type}) \n",
    "\n",
    "        if((epochs+1)%10 == 0):\n",
    "            model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Saving trained model last time....\n",
    "model.save('model.h5')\n",
    "# model.save('model_best.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking on test data split....  25 %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing data has 1224607 observations\n"
     ]
    }
   ],
   "source": [
    "test_size = file_len(testfile)\n",
    "print('Testing data has',test_size, 'observations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "curr_test_data :  0 : 100000\n",
      "100000/100000 [==============================] - 3s 29us/step\n",
      "curr_test_data :  100000 : 200000\n",
      "100000/100000 [==============================] - 3s 27us/step\n",
      "curr_test_data :  200000 : 300000\n",
      "100000/100000 [==============================] - 2s 24us/step\n",
      "curr_test_data :  300000 : 400000\n",
      "100000/100000 [==============================] - 4s 40us/step\n",
      "curr_test_data :  400000 : 500000\n",
      "100000/100000 [==============================] - 2s 20us/step\n",
      "curr_test_data :  500000 : 600000\n",
      "100000/100000 [==============================] - 2s 24us/step\n",
      "curr_test_data :  600000 : 700000\n",
      "100000/100000 [==============================] - 2s 20us/step\n",
      "curr_test_data :  700000 : 800000\n",
      "100000/100000 [==============================] - 2s 21us/step\n",
      "curr_test_data :  800000 : 900000\n",
      "100000/100000 [==============================] - 1s 9us/step\n",
      "curr_test_data :  900000 : 1000000\n",
      "100000/100000 [==============================] - 1s 11us/step\n",
      "curr_test_data :  1000000 : 1100000\n",
      "100000/100000 [==============================] - 1s 12us/step\n",
      "curr_test_data :  1100000 : 1200000\n",
      "100000/100000 [==============================] - 1s 12us/step\n",
      "curr_test_data :  1200000 : 1224606\n",
      "24606/24606 [==============================] - 0s 17us/step\n"
     ]
    }
   ],
   "source": [
    "batch_size = 100000\n",
    "currpos = 0\n",
    "params_net = None\n",
    "divcount = 1\n",
    "while(True):\n",
    "    \n",
    "    nextpos = currpos + batch_size\n",
    "    if(nextpos > test_size-1):\n",
    "        nextpos = test_size-1\n",
    "        \n",
    "    print(\"curr_test_data : \" ,currpos,':', nextpos)\n",
    "    batch = readlines(trainfile, currpos, nextpos)\n",
    "    # batch = rmreadlines(testfile, batch_size)\n",
    "\n",
    "    batchdf = pd.DataFrame(np.array(batch)).astype(float, errors='ignore')\n",
    "\n",
    "    for col in batchdf.columns:\n",
    "        batchdf[col] = batchdf[col].astype('float64', errors = 'ignore') \n",
    "\n",
    "    batcharr = batchdf.values\n",
    "\n",
    "    X = batcharr[:,:-1]\n",
    "    Y = batcharr[:,-1]\n",
    "\n",
    "    Y_num = np.ones(Y.shape)\n",
    "    Y_num[Y == 'normal.\\n'] = 0\n",
    "\n",
    "    Y_cat = Y_num.copy()\n",
    "    Y_type = Y_num.copy()\n",
    "    for i in label_list['type']:\n",
    "        Y_cat[Y == i+str('.\\n')] = label_list[label_list['type'] == i]['id_cat']\n",
    "        Y_type[Y == i+str('.\\n')] = label_list[label_list['type'] == i]['id_type']\n",
    "\n",
    "    Y_num_hot = one_hot(Y_num.astype(int), 2)\n",
    "    Y_cat_hot = one_hot(Y_cat.astype(int), 5)\n",
    "    Y_type_hot = one_hot(Y_type.astype(int), 23)\n",
    "\n",
    "    X_new_hot = np.delete(X,[1,2,3],1)\n",
    "\n",
    "    params = model.evaluate(X_new_hot,{\"y1out\": Y_num_hot, \"y2out\": Y_cat_hot, \"y3out\": Y_type_hot}, batch_size = 1000) \n",
    "\n",
    "    if params_net is None :\n",
    "        params_net = np.array(params)\n",
    "    else:\n",
    "        params_net += np.array(params)\n",
    "        \n",
    "    if(nextpos == test_size - 1):\n",
    "        break;\n",
    "    else:\n",
    "        currpos += batch_size\n",
    "        divcount += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "lossacc = params_net/divcount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Test Losses, net_loss : 0.2997794203976902 , y1 : 0.0434200704401108 , y2 : 0.09555967983587535 , y3 : 0.04892640265353351\n",
      "Final Test Accuracies, y1 : 0.990520032194782 , y2 : 0.989020031699605 , y3 : 0.9776115703443591\n"
     ]
    }
   ],
   "source": [
    "print('Final Test Losses, net_loss :',lossacc[0],', y1 :', lossacc[1], ', y2 :', lossacc[2], ', y3 :', lossacc[3])\n",
    "print('Final Test Accuracies, y1 :', lossacc[4], ', y2 :', lossacc[5], ', y3 :', lossacc[6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thankyou for viewing"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
